{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv('saved_paragraphs.csv')\n",
    "org_data = pd.read_csv('original_paragraphs.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import spacy\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "import torch\n",
    "def search_paragraphs(query, paragraphs):\n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "    # Load Sentence Transformer model\n",
    "    model_name = \"all-mpnet-base-v2\"\n",
    "    sentence_transformer = SentenceTransformer(model_name)\n",
    "\n",
    "    # Extract content from the list of tuples\n",
    "    paragraph_contents = [content for idx, content in paragraphs]\n",
    "\n",
    "    query_embedding = sentence_transformer.encode([query])[0]\n",
    "\n",
    "    # Calculate paragraph embeddings\n",
    "    paragraph_embeddings = sentence_transformer.encode(paragraph_contents)\n",
    "\n",
    "    # Calculate cosine similarity\n",
    "    scores = util.pytorch_cos_sim(torch.tensor([query_embedding]), torch.tensor(paragraph_embeddings))[0]\n",
    "    scores = scores.cpu().numpy()\n",
    "\n",
    "    # Get the indices of top results\n",
    "    top_indices = scores.argsort()[::-1][:5]\n",
    "\n",
    "    # Create a list of tuples with score, index, and content\n",
    "    top_results = [(scores[idx], idx, paragraphs[idx][1]) for idx in top_indices]\n",
    "\n",
    "    return top_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "paragarphs=[]\n",
    "cnt = 0\n",
    "entity_graphs = []  # Replace with actual entity graphs\n",
    "for i in data['para_content']:\n",
    "    #entity_graphs.append(generate_entity_graph(i))\n",
    "    #print(i)\n",
    "    \n",
    "    paragarphs.append((cnt,i))\n",
    "    cnt = cnt + 1\n",
    "   # print(paragarphs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "67"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(paragarphs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paragarphs[1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import silhouette_score\n",
    "import re\n",
    "import re \n",
    "from unicodedata import normalize\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "def text_normalization(text):\n",
    "    \"\"\" \n",
    "    Perform text normalization on a paragraph of text.\n",
    "    \n",
    "    This involves:\n",
    "    - Lowercasing \n",
    "    - Fixing whitespace issues\n",
    "    - Removing punctuation\n",
    "    - Expanding contractions\n",
    "    - Removing accented characters\n",
    "    - Lemmatizing text  \n",
    "    - Removing stop words\n",
    "    \n",
    "    It returns the normalized text as a string.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Fix whitespace\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    \n",
    "    # Remove punctuation    \n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    \n",
    "    # Expand contractions\n",
    "    contractions = {\"ain't\": \"am not\", \"aren't\": \"are not\"} \n",
    "    text = text.replace(\"n't\", \" not\")\n",
    "    text = re.sub('|'.join(contractions.keys()), \n",
    "                  lambda x: contractions[x.group()], text) \n",
    "    \n",
    "    # Remove accented characters\n",
    "    text = (normalize('NFKD', text)\n",
    "                  .encode('ascii', 'ignore')\n",
    "                  .decode('utf-8', 'ignore'))\n",
    "    \n",
    "    # Get root form of words (lemmatize)\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    text = ' '.join([lemmatizer.lemmatize(word) for word in text.split()])\n",
    "    \n",
    "    # Remove stop words\n",
    "    stop_words = set(stopwords.words('english'))  \n",
    "    text = ' '.join([word for word in text.split() \n",
    "                    if word not in stop_words])\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-2-99e6bb7af851>:21: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
      "  scores = util.pytorch_cos_sim(torch.tensor([query_embedding]), torch.tensor(paragraph_embeddings))[0]\n"
     ]
    }
   ],
   "source": [
    "# Search query\n",
    "user_query = \"\"\"There is some guy who made a project for pringing and etc\"\"\"\n",
    "\n",
    "# Call the search function\n",
    "result = search_paragraphs(user_query, paragarphs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search Query: There is some guy who made a project for pringing and etc\n",
      "Score: 0.4448288381099701\n",
      "Paragraph:\n",
      "\"I am a great inventor, you must know, andI manufacture my products in this lonely spot. \"\"What are your products?\" enquired the Wizard.\n",
      "-----------------------------\n",
      "Score: 0.3671092987060547\n",
      "Paragraph:\n",
      "A simple example is modeling a sequence of days with sunny or rainy weather, where the weather on a given day is randomly determined based solely on the weather of the previous day. This pure probabilistic approach enables modeling phenomena from physics, biology, and beyond for theoretical and practical insights. This establishes a lightweight, yet versatile approach compared to heavy parameterization with neural networks. By optimizing cumulative future reward, the model learns probable transitions between words reflecting sensible narratives. For example, initializing the state with \"Alice was\" and sampling subsequent actions as words yield:\"Alice was heading to the store when...\"\"Alice was shocked to discover that...\"\"Alice was running late for her appointment...\"The model associates those sentences starting with the phrase \"Alice was\" which commonly transitions towards other verbs or plot-advancing events. Their efficient yet effective learning drives adoptions in chatbots for dialog modeling or summarization systems for extracting key points - producing sensible language output without laborious feature engineering. A very simple example is estimating  - we could generate random (x,y) points on a square enclosed in a circle and count what fraction falls inside the circle to estimate its area relative to the square. As the number of samples increases, the estimate converges to , based on area geometry. Common applications include pathfinding, decision tree learning, and evaluating multidimensional integrals in physics simulations that are too complex to solve analytically. The algorithms are useful since they are often easier to implement than deriving explicit solutions while providing great flexibility. Together they provide a versatile yet lightweight framework to model real-world stochastic processes like financial trends, genome sequencing, and social networks. MCMC in layman's termsMCMC is like playing a board game to explore new places. Imagine you are playing Snakes and Ladders. Your piece starts at the beginning. Where you land next depends only on your current spot - if you land at the bottom of a ladder, you climb up and advance faster! Now let us add dice rolling like in Monopoly. This randomness helps you explore more spots, not only the connected ones. This way you get to know the board better compared to moving along just adjacent squares! It allows studying huge complex game boards by directly hopping between interesting features through many simulated traversals, something too long by standard play. Consider training a robot to navigate obstacle courses. The state space encoding positions and sensor data are enormous - far too large to explore exhaustively in a reasonable time. After sufficient simulation iterations, high-reward state-action sequences are discovered without prohibitively expensive physical trial-and-error. \n",
      "-----------------------------\n",
      "Score: 0.3629254102706909\n",
      "Paragraph:\n",
      "We discuss these results and providerecommendations related to curriculum development, assessmentmethods, and pedagogical practice. We are particularly in- RQ3 : II. [9],and even produce programming assignments [1], [4]. So while a phaseshift appears to be underway, it is a critical moment to ensurethat things are changing for the better and not for the worse. B. Carefully account-ability. They havealso led to the creation of new conferences that focus onfairness, accountability, and transparency. For instance, XAI has grappled withquestions like explainable to who and for what purpose [28]. Basedon these threads of research, understanding stakeholders iscrucial for developing AI systems that are comprehensible,trustworthy, and avoid excessive reliance. III. This qualitative research method is oftenused to elicit participants’ perceptions, experiences, and valuesregarding a particular topic or technology [35]. Once the thematic analysis wascompleted for all of the interviews, both researchers comparedand combined themes through mediation.  However, priorwork has shown that results obtained from qualitative studieswith small sample sizes can still provide valuable insights forthe topic being researched [44], [45]. IV. I’d rather ChatGPT do it, because it will. ” They said,Fig. 1. There’s the answer. ’ It will give youfalse information. It keepsme on my toes, and makes sure I double-checkeverything. I can’t rely too much on it. ”  Participants S3 and S8 specifically mentioned one wayto avoid plagiarism would be to increase the number of examsor the weight of exams in the final grades of courses. yeah, you could do it, but do you want to? V. R ESULTS - THEMES FROM INSTRUCTOR INTERVIEWS And come up with new waysto assess. But then the job of thestudent is not simply to return the report, but instead,look at the report ChatGPT wrote, and then decideor criticize whether it’s right or wrong, and then,if it’s wrong, then what is wrong with it, or try toimprove... Additionally, participant I5 said,“Just the production of something is not going to beas important, perhaps leaning more into analysis,perhaps leaning more into your ability to trou-bleshoot. Versus creation which is one of which isone of the steps that you know of many steps in anysort of understanding or building a system or analgorithm or a data structure or anything else. ... •Continue to give proctored exams since they can’t beplagiarized like other out out-of-class assignments (I4)VI. ACKNOWLEDGMENTWe would like to thank Dr. Brian McInnis for feedback onthe abstract which helped refine the final framing of the paper. of the 2022 ACM Conf. on Int. of the 2022 ACM Conf. on Int. ACM, 2022, p. 37–39. 931–937. SIGCSE 2023, 2023. 1 , ser. ITiCSE 2023. on Int. 563–569. 2 , ser. SIGCSE 2023. 103, p. 102274, 2023. 2 , ser. ITiCSE 2023.  The MIT Press, 2008. 126–136, 2016. 456–462, 1985. Frontiers Media SA, 2020, p. 128. 41–63, 2015. 8, no. 2, 2021. AIED 2018. 75 264–75 278, 2020. Sci. 38, no. 1, 2022. [26] P. Denny, V . Towardsa reflective sociotechnical approach,” in HCI International 2020-LateBreaking Papers: Multimodality and Intelligence: 22nd 449–466. 50–80, 2004. 407–434, 2015. 133–144, 2022. 3, p. 100074, 2022. 6–7, 03 2015. Comput. no. 1, oct 2021. ICER ’09. ICER ’16. [40] S. Mirhosseini, A. Z. Henley, and C. Parnin, “What is your biggestpain point? 1 , ser. SIGCSE 2023. 1–9. [42] D. Magaldi and M. Berler, “Semi-structured Interviews,”in Encyclopedia of Personality and Individual Differences ,V . Zeigler-Hill and T. K. Shackelford, Eds. 4825–4830. Braun and V . 77–101, 2006. 1–9. 425–440, 1996. [47] D. Long and B. Magerko, “What is ai literacy? CHI ’20. Rep., 1991, iSBN: 9781878380081 ISSN: 0884-0040 ERIC Number:ED336049. Rep., 2005,publication Title:  What is your major? What year are you? Whatkinds of classes have you taken? How manyyears have you been teaching?  2) What types of coursework/assignments do youfind yourself needing assistance on? 4) 5) 6) 7)\n",
      "-----------------------------\n",
      "Score: 0.34016865491867065\n",
      "Paragraph:\n",
      "[3] M. Wermelinger, “Using github copilot to solve simple programmingproblems,” in Proceedings of SIGCSE . Kumar, and N. Giacaman, “Conversing with copilot:Exploring prompt engineering for solving cs1 problems using naturallanguage,” 2022.\n",
      "-----------------------------\n",
      "Score: 0.29803338646888733\n",
      "Paragraph:\n",
      "Generative AI in Computing Education:Perspectives of Students and InstructorsCynthia ZastudilComputer & Information SciencesTemple UniversityPhiladelphia, PAcynthia.zastudil@temple.eduMagdalena RogalskaComputer & Information SciencesTemple UniversityPhiladelphia, PAm.rogalska@temple.eduChristine KappComputer & Information SciencesTemple UniversityPhiladelphia, PAchristine.kapp@temple.eduJennifer VaughnComputer & Information SciencesTemple UniversityPhiladelphia, PAjennifer.vaughn@temple.eduStephen MacNeilComputer & Information SciencesTemple UniversityPhiladelphia, PAstephen.macneil@temple.eduAbstract —Generative models are now capable of producingnatural language text that is, in some cases, comparable in qualityto the text produced by people. In the computing educationcontext, these models are being used to generate code, codeexplanations, and programming exercises. The rapid adoptionof these models has prompted multiple position papers andworkshops which discuss the implications of these models forcomputing education, both positive and negative. This paperpresents results from a series of semi-structured interviews with12 students and 6 instructors about their awareness, experiences,and preferences regarding the use of tools powered by generativeAI in computing classrooms. The results suggest that GenerativeAI (GAI) tools will play an increasingly significant role incomputing education. However, students and instructors alsoraised numerous concerns about how these models should beintegrated to best support the needs and learning goals ofstudents. We also identified interesting tensions and alignmentsthat emerged between how instructors and students prefer toengage with these models. As GAI tools become in-creasingly prevalent, it’s important to understand educationalstakeholders’ preferences and values to ensure that these toolscan be used for good and that potential harms can be mitigated. Index Terms —Generative models, large language models, com-puting education, student perceptions, instructor perceptionsI. I NTRODUCTION The introduction of Generative AI (GAI) models has ledto significant excitement in the computing education com-munity [1]–[10]. These generative models are typically pow-ered by large language models such as GPT-3 or Codexwhich are capable of producing code explanations [5], [6],[9] that have been rated as being better than peer-generatedexplanations [9]. In addition, these models can solve basicprogramming assignments [1], [7] and perform slightly worsethan students on quizzes with multiple-choice questions [8]. Understandably, these substantial and rapid advances in theperformance of generative models are causing excitementand consternation among students and instructors. A recentbirds of a feather discussion at the SIGCSE conference [11]highlighted a few emerging concerns that educators haverelated to over-reliance, plagiarism, and other forms of misuse. These concerns have been echoed by position papers [7], [12],a working group [13], and an investigation into instructorperspectives [14]. However, these concerns only scratch thesurface, there is an urgent need to understand students’ andinstructors’ preferences about and what they want from theseGAI tools so that future development and regulation can alignwith the values of these critical stakeholders. In this paper, we conduct an interview study with 18participants including both students (N=12) and instructors(N=6). The goal of this interview study is to better understandthese two key stakeholders’ awareness of these models andtheir preferences about how these models should be usedin computing education classrooms. terested in what ways students and instructors envision theinvolvement of generative AI in computing education, bothpositively and negatively. In this paper, we investigate three research questions:RQ1 : What preferences do instructors and students haveregarding how Generative AI should be used in comput-ing education classes? RQ2 : What concerns do instructors and students have re-garding the use of Generative AI in computing education? What implications might Generative AI have oncomputing education curricula, pedagogy, and assessmentmethods? The results from our study suggest that students and in- structors believe computing course curricula and assessmentmethods should be updated to include GAI tools; however,there are important challenges which need to be addressed inorder to use them successfully while reducing their potentialharm to instructors and students alike. These results providearXiv:2308.04309v1  [cs.HC]  8 Aug 2023a timely and important snapshot of students’ and instructors’perspectives and preferences which can inform the design ofpedagogies, tools, and policies that best align with students’preferences and needs. R ELATED WORKA. An AI Phase-Shift in the ClassroomLess than three decades ago, widespread access to theInternet fundamentally changed the education landscape. Asinternet access in the United States rose from 14 to 77 percent,students could suddenly access educational resources, playeducational games, and interact with peers in online learningcommunities. This inequitable access to these resources alsoled to a digital divide where some students were left behindbecause they did not have personal computers or reliableinternet access [15]. Recent advances in AI are poised to createa similar phase shift in the education landscape. AI-poweredtools are becoming ubiquitous both in online and face-to-facelearning environments. From a student’s perspective, these AI-powered tools provide a number of important benefits suchas an increased awareness of their performance, personalizedlearning pathways [16], and personalized support in the formof intelligent tutors [17], [18]. From an instructor’s perspec-tive, learning analytics tools provide instructors with the abilityto monitor student activity and adapt their teaching [19]–[22]. Some of these tools are even integrated into classroomenvironments where instructors can use augmented reality tomonitor student learning, metacognition, and behavior in real-time [23]. discuss additional ways in which AIin the classroom can be beneficial for instructors such asin improving student reviews, grading, and feedback, utiliz-ing intelligent tutoring systems, and improving pedagogicalpractices and student experiences using AI-powered VR forexperiential or practical learning experiences [24]. However, many of these advances have been limited bythe current abilities of machine learning. Recent advances inmachine learning have introduced generative models capableof understanding and generating code have crucial implicationsfor computing education. Researchers are already demonstrat-ing the capabilities of these models to help students generatecode [3], [25], [26], explain code to students [5], [6], However,there are also some emerging challenges related to over-reliance and plagiarism [5], [11]. For instance, a recent studyshowed how these models can perform nearly as well asstudents on multiple-choice questions [8]. Considering the Design of AI Systems The introduction of AI systems has led to new designchallenges related to their probabilistic nature, their lack oftransparency, and their issues related to fairness and These challenges have led to rapidly evolving researchtopics such as explainable AI (XAI), human-AI interaction(HAII), and human-centered machine learning. Across these fields,there is a resounding call to focus on approaches that arehuman-centered [27]. Additionally, people calibrate their trust through interactionsand experiences with the AI system [29]; however, otherfactors such as age, culture, and personality can also affecttrust in AI systems [30]. Numerous computing education researchers are already ad-dressing these issues of explainability, trust, and over-reliance. Their framework outlined 6 importantfactors to consider when building XAI: who the stakeholdersare (e.g., instructors and students), what benefits stakeholdersreceive from interacting with the system, what potential issuesstakeholders may encounter when using the system, howexplanations are presented, what AI models are used, and thebest ways to design user-friendly and effective AIED systems. However, the usage of GAI tools in education, suchas ChatGPT and GitHub Copilot, poses a unique problem, asthey were not developed solely for an educational purpose andtheir inclusion in the classroom may have unknown effects. Many researchers have begun to explore the potential negativeeffects the inclusion of these models into education may bring,including bias and fairness of these models, over-reliance,explainability, and trust [7], [11]. M ETHODOLOGYTo investigate our research questions about student and in- The field ofcomputing education has begun adopting interview studies[36]–[39], often to explore the perspectives of instructorsor students with respect to topics such as instructor painpoints [40] or student perspectives about online versus on-site teaching [41]. In this study, we focus on the perspectivesof both instructors and students because it is critical to includeall relevant stakeholders when considering the implications ofnew technology such as generative AI.A. Participant DemographicsWe conducted interviews with students (N=12) and instruc-tors (N=6) which resulted in 18 total interviews. Theinstructors included a mix of tenure-track and teaching-trackfaculty. Students were recruited through student organizations,flyers, and snowball sampling. All of the instructors interviewed taughtcomputer science courses. Two researchers followed thisprocess independently, then compared codes in order to helpmitigate interpretation biases. There is currently an urgent need to understand the im-plications of generative AI in computing education. For ex-ample, researchers and practitioners are already raising con-cerns about over-reliance, academic misconduct, and modeltrustworthiness This work serves as an early probeinto understanding current preferences, values, and concerns. While limited in scope, our work provides a preliminaryinvestigation in order to help instructors, researchers, and morequickly adapt to this changing landscape. The participants ofthis study, both instructors and students, came from a singleR1 university and represent a relatively small sample size,and as such, these results may not fully represent differentdemographics across different universities. R ESULTS - THEMES FROM STUDENT INTERVIEWS In this section, we present the themes that emerged from ourstudent interviews. A summarized version of the results frominterviews with both stakeholders (students and instructors)can be found in Figure 1.Within each theme, we present sub-themes, our observations, relevant supporting quotes, and rela- tionships between the theme and our three research questionspresented in the introduction. Despite focusing our questionson Generative AI (GAI) tools such as GitHub Copilot, Codex,and Grammarly, our participants tended to focus on ChatGPT. A. Perceived Benefits of GAI Tools (RQ1)Students shared the ways in which they have found GAITools to be beneficial in their computing courses, as well astheir potential uses in computing education. GAI tools reduce the effort to write code and findlearning materials. Most students (10/12) believed that GAItools, such as ChatGPT, have the potential to become, andin many cases are already, valuable learning tools to reducethe effort for students and instructors to complete somecommon programming tasks and find learning materials. Ofthe remaining two students, one was not very familiar withGAI tools and was therefore unsure of their value and theother actively tried to avoid using them. Students shared a number of ways in which they have foundGAI tools useful in the computing education context:•Generating skeleton or boilerplate code (S2, S3, S8, S9) •Generating explanations of code (S2, S6, S7, S10, S11) Reflecting on how GAI tools can generate examples to sup-plement existing learning materials, S2 said,“[Students] can use [ChatGPT] to find resourcesonline... Students use GAI tools to avoid busy work. When askedwhat motivates students to use these tools, students who fre-quently use them expressed that they were more likely to useGAI tools for assisting with, or even completing, assignmentsthat they perceived as “meaningless” or mere “busy work.” Some students (4/12) compared it to existing tools, such asthe calculator, whose introduction into the classroom allowedstudents to progress towards more advanced topics faster andreduce the amount of time students have to spend on familiartasks or could be considered tedious [46]. According to someof the students, this refers to any work that takes too much oftheir time for very little academic benefit or that they aren’tpassionate about. Participant S2 remarked on what kind ofwork they use ChatGPT for the most, saying,“ChatGPT could just kind of do all the busy workor anything I could figure out, in like a couple ofminutes. GAI tools shift the focus to higher levels of abstraction. Students expressed (6/12) that GAI tools could help reduce theamount of time spent working at lower levels of abstraction. Students often gave examples of how GAI tools could shift thelearner’s focus toward higher-level skills (e.g., design, the anal-ysis and evaluation of code, or advanced software engineeringconcepts) which students are more likely to encounter in latercomputing courses. For example, participant S9 described howstudents might focus on design patterns and software designrather than implementation details. On the left, summarized themes from student interviews are presented and, on the right, summarized themes from instructor interviews are presented. “You don’t usually get design patterns until you arein graduate school, right? Unless you’d specificallyseek it out...we could use ChatGPT to help teachdesign patterns where... You can use ChatGPT as atool to implement all the little pieces. But we aregoing to try to break down this larger problem tofigure out what pattern applies to it, and then usewhatever you need to use to generate the individualpieces of code. But we really care about the overallstructure and making sure that the students kindof have this broader understanding of the piece ofsoftware rather than a single algorithm or a singlepiece of code or a smaller scale program. ” GAI tools provide alternative perspectives and sourcesof assistance. Another common theme amongst students whoregularly use GAI tools is that these tools provide anothersource of assistance outside and their instructors and teachingassistants (4/12). Some reasons why students said they chooseto use a tool such as ChatGPT rather than asking theirinstructors or teaching assistants are:•Some professors are not good at explaining course con-cepts and code (S4, S5)•GAI tools can provide multiple and alternative perspec-tives about programming concepts (S5, S10) •GAI tools can be more convenient sources of assistanceover instructors or TAs (S5, S8) S4 described a time in which they wished they were able touse GAI tools in order to get more help with a concept inone of their computing courses, especially when they foundthemselves searching for a different perspective when they felttheir instructor wasn’t communicating what they needed,“With some professors, they don’t know how tocommunicate the answer that you’re looking for...I had a lot of trouble wrapping my head around itwhen I asked in what context will we use a linkedlist. [My Instructor] just explained what a linkedlist was, and with ChatGPT, I feel like I could say,‘give me an example of a linked list and how I wouldimplement it in this language, ’ ” B. Concerns about GAI Tools (RQ2) While students largely expressed excitement about GAItools’ benefits to computing education , students also expressedan amount of trepidation and concern regarding their use incomputing education. Concerns about over-reliance. Most students (9/12) men-tioned the potential for students to develop an over-relianceon these tools as a concern. More specifically, students (6/12)detailed their concerns about the quality of education studentsreceive if they become over-reliant on GAI tools that don’tadequately explain their responses. Some of the specific con-cerns about over-reliance and the quality of education were:•Students may not develop an understanding of the ma-terial when they get assistance from GAI tools (S1, S4,S5, S9, S11, S12) The following quotes from participants further illustrate someof these student concerns. Participant S1 said,“When using them I don’t really fully understandwhat they’re telling me, and it’s just kind of like,‘Oh! But I’m not really the onelearning and really digesting what’s happening andhow I got to that conclusion. ” Participant S4 provided an additional perspective, saying,“I feel like a lot of people just heavily rely on it, andthey use it to just copy and paste the work, and notnecessarily understand why. I feel like they wouldjust copy the work given to them. It kind of ruinsthe purpose of learning it in the first place. ” Concerns about trustworthiness. The majority of students(7/12) also expressed concerns about the trustworthiness ofthe output given by GAI tools. Students raised concerns aboutthe reliability of information generated by these models dueto their potential to misinform students. Specifically, studentsoutlined the following concerns about trustworthiness:•Information sources are missing or incorrect (S1, S8, S9) •GAI tools tend to hallucinate information (S6, S8, S10)•Students have to double-check everything, not just infor-mation, but things like false context and tone (S4, S6)Participant S8 said, due to these models’ tendency to hal-lucinate students have to be careful to double-check theinformation they receive,“[ChatGPT] is helpful, but I understand that some-times it also hallucinates as well. I don’t really know if it is yetlike a Google replacement..., I feel like it’s only asuseful if you really know the topic that you’re talkingabout, and like you can read what it’s saying, and besure that it’s not like [meaningless output], becausesometimes you do have to search again on Googlejust to make sure what it said is correct. ” Participant S4 also described needing to check responses forcorrectness, sharing that it wouldn’t stop them from using GAItools altogether and it prevents them from relying on the toolstoo much,“[Incorrect ChatGPT responses] wouldn’t keep mefrom using it again. It’s just a small detail. Concerns about academic integrity. These students expressed the belief that the amount of plagia-rism will increase as these tools become more popular. However, students did not necessarily believe that AI-aidedplagiarism is all that different from plagiarism that occurredpreviously. Students claimed that the only difference betweenplagiarizing by copying someone else’s work or paying fora subscription service such as Chegg and using a tool likeChatGPT is that it’s free and available to everyone. “Before I’ve seen people use things like, Chegg, tojust straight up just finish their homework. I feel likeit’s just a difference between you using ChatGPT,which is a free service, and it can give you theinformation you want, and you could probably justchange up a couple of things with it versus payinga fee for a subscription-based service that just hoststhe work that your professors are giving to you. ” (S4)C. Predicted Implications of GAI Tools (RQ3) Students were excited to share their insight about howcourse curricula and assessment methodologies should beadapted to accommodate GAI tools. Instructors are responsible for adapting their courses. Inour interviews, none of the students said that instructors shouldban the use of GAI tools. On the contrary, multiple students(5/12) expressed that instructors are responsible for adaptingtheir courses in ways to work with this new technology, asinstructors have had to in the past with any innovative andpopular technology, such as calculators, Wikipedia, and theInternet (4/12). While the majority of students expressed thatthey were not sure exactly what steps need to be taken byinstructors in order to adapt their classes, a couple of studentsindicated updates they hope instructors do notmake to theirclasses. However,both students said they would not want this,“I guess they would have to possibly lower labweights and maybe increase exam weights, or youknow things that can be more so tested in person... Ifeel like it shouldn’t be like that... I kind of had thebenefit of, like, you know, being able to use Google,having like a 40-50% like lab weight. Being able touse Google, learn, read a lot of documentation, andyou know, actually, kind of somewhat suffer throughlabs, but also I knew that the lab grade would saveme because I wasn’t as good on exams, ” (S8) Instructors must focus on student engagement. Severalstudents (3/12) specifically mentioned that, when learning newmaterial, hands-on active-learning assignments are the mosthelpful and engaging. Students (4/12) emphasized that theybelieved that engaging courses and coursework would morelikely result in engaged students who see value in and wantto complete the assignments and are less likely to plagiarize. Participant S1 said the following,“Instructors need to understand why students useChatGPT in the first place, and some of the reasonswhy they use it is they just don’t understand thecontent, and they want an easy out and that meansthat something is going wrong with the curriculumthat’s being presented to them. ” Instructors should incorporate GAI tools into the classes. Students were excited about the potential for instructors toinclude these models in their curricula. Students suggestedthat instructors could focus less on implementation detailsand more on high-level concepts. Participant S5 pointed tothe importance of other skills that should be learned in earlyprogramming courses, particularly problem-solving. “I think learning the language is the easiest part, but I think the introductory programming coursesoffer something a little bit more important, which isproblem-solving. Which I think will still ... be a veryimportant part of programming, because that’s reallyall programming is. It’s just problem-solving... Butthe problem-solving mindset is definitely somethingthat cannot just be assumed people have. ” Students (4/12) also suggested that instructors could teachstudents how to use GAI tools by teaching students the bestways to prompt tools such as ChatGPT and the limitationsand risks of using these tools. A couple of students alsosuggested instructors could use GAI tools to scaffold learning,as described in more detail by participant S5,“It’s like asking a mathematician to do mundanerepetitive math equations today without a calcula-tor... Notreally. So, I think instructors should, you know, startoff teaching their students, you know, how to do it. How to do everything without an AI language modelto help them. And then, as they get more advancedwith it, they, you know, introduce the AI to just, youknow, make the more difficult tasks a bit easier. ” The following section details the themes and observationsdiscovered through our instructor interviews. Similar to stu-dents, instructors tended to focus primarily on ChatGPT. A. Perceived Benefits of GAI Tools (RQ1) While instructors (5/6) have not used GAI tools frequently,they envision a number of ways in which they can be beneficialfor students in computing courses. Overall, instructors werefamiliar with GAI tools like ChatGPT and GitHub Copilot,but used them much less than students. Consequently, theyhad fewer insights about they might be used in the computingeducation context. However, every instructor (6/6) thought thatthese tools could be valuable for students. GAI tools can help students understand code and com-puting concepts. A couple of instructors (2/6) thought thatGAI tools were beneficial for students when they encounterunfamiliar code and that GAI tools could provide just-in-timesupport. While prior work has demonstrated the ability ofgenerative AI to explain code, participant I2 described how thishelps students when they encounter unfamiliar code online,“You can give [ChatGPT] a little piece of a programyou got from Github or whatever, and have it explainto you what this code is doing, and it would do agood job. ” GAI tools can help students find inspiration, brainstorm,and get feedback on ideas. A majority of the instructors(4/6) detailed ways in which GAI tools could be used to aidin creative processes such as ideation and brainstorming. Forexample, participant I1 described how GAI tools can helpwith brainstorming solutions to coding problems. Additionally,some instructors (2/6) described ways in which they’ve foundsuccess in having GAI tools, specifically ChatGPT, providestudents with feedback on their writing for project-basedcomputing courses. Participant I2 described how they’ve hadstudents use ChatGPT to try to find weaknesses or areas ofimprovement for their essays or project proposals. GAI tools’ low cost and accessibility can provide stu-dents with high quality learning resources. A couple ofinstructors (2/6) expressed their excitement about how the lowcost and barrier to entry can provide students with resourcesthat can be prohibitively expensive, such as private tutors orpaid services such as Chegg or CourseHero. Additionally, GAItools could act as high quality learning resources outside ofstudents’ instructors and TAs, providing another perspectiveon course topics. B. Concerns about GAI Tools (RQ2)Instructors hold many common concerns regarding AI sys-tems for the use of generative AI in computing education andtheir use by students. Concerns about trustworthiness. Most of the instructors(5/6) cited the lack of trustworthiness of responses from GAItools as one of their primary concerns. All of the instructorsmentioned that it’s important to double-check the informa-tion received from these models. However, as one instructorpointed out, students don’t always have the necessary foun-dational knowledge to know whether the outputs are right orwrong. Participant I4 said,“We don’t know that [ChatGPT] is giving [students]the right information. and you know, if I know atopic, I know when I’m getting bogus information. They don’t, you know, so that’s a concern. ” Concerns about over-reliance. Several instructors (3/6)also cited over-reliance as a significant concern when consid-ering students using these models in their classes. ParticipantI3 expressed concern about students not fully learning materialif they rely too heavily on GAI tools. Participants I1 andI3 both expressed concern that students may lose importantskills, such as writing, if they become too reliant on thesemodels. Participant I5 discussed their concern about GAI toolsreplacing students’ own effort, saying,“I think pedagogically, we’ll have to kind of go backto the drawing board. Not necessarily just to prevent studentsfrom using and benefiting from these tools, by allmeans we should embrace change and new methodsand new ways of doing things. So find ways wherestudents can use these things to assist, to help butnot one where it replaces their own cognitive load. ” Concerns about academic integrity. All instructors (6/6) ex- pressed concern about students using GAI tools to plagiarize. Several instructors (4/6) expressed that, due to the availabilityand low cost of tools like ChatGPT, students are likely toplagiarize more. However, one instructor (I5) said,“I feel like a student who was never motivatedto cheat in the first place will not do it now justbecause ChatGPT is available. Sufficiently motivatedstudents would have always cheated. So if I were tolazily assume that there is an uptick in the numberof students who are now exploiting this tool oran uptick in the number of students who are nowcheating as a result of this tool, it would havebeen those in the middle who were always willingto, but perhaps lack the time, resources, access,or the know-how to properly engage in it, but Idon’t think just there’s this giant movement towardsmore students doing it, who would not have doneit otherwise. I don’t think it’s turning students intocheaters. I think it’s just making it more accessibleto those who already would have done it. ” This participant’s insight aligns with the perspectives sharedby the other instructors in that, the concerns about academicintegrity which have arisen due to the presence of GAI tools inthe classroom, are less focused on just stopping students fromcheating, which is unlikely, but rather in developing ways inwhich instructors can disincentivize cheating. C. Predicted Implications of GAI Tools (RQ3)Instructors shared uncertainty about what exactly needs tochange in course designs and assessment methods; however,they emphasized the importance of proactively incorporatingthese models into computing education curricula. GAI tools should be incorporated into classrooms. Unanimously, instructors (6/6) emphasized that they believeGAI tools should not be banned, and they should embracetheir existence and include them in the classroom. Instructorsbelieved it was imperative to understand how these tools work. Some of the ways they envisioned incorporating GAI tools intotheir courses included:•Let students use it but they should be able to explain whythe output is correct or incorrect (I1, I3, I6)•Clearly articulate what students need to know how to dowithout using GAI tools (I4)Participant I4, detailed how, with any new tools which shifthow courses are taught, clear expectations for students needto be established,“... before calculators were a thing we used to expectstudents to memorize multiplication and divisiontables. And you know, after the calculator cameinto being, of course, you know it’s reasonable notto expect people to memorize that when you knowthey’ve got a tool that they can use to figure outhow to multiply things, you know. And I could seethe same thing happening with us with programmingnow that tools like ChatGPT exist, you know, maybethere are certain things that we could expect studentsto use a tool for, and we don’t have to test them onit. But at the same time, you know, there has to besome core level of knowledge that we should expectfrom a student, you know, without the use of tools. ” GAI tools can facilitate critical thinking A couple ofinstructors (2/6) were excited about the potential to use thesemodels in their courses to help students further develop theircritical thinking and analysis skills. Participant I6 said,“ Let them actually use ChatGPT to come back witha report as a first draft. So in that sense, it is more useful for thestudent to develop their critical thinking... instead ofjust like the old way of just writing a report. ” It’snot, give me code, it’s, here is some code, give mesome sort of analysis that matches or fits into some-thing that is not easily template-tized, something thatis not easily described or describable. ” Instructors need to update assessment methods. In termsof how to update curriculum to adapt courses to account forthe existence of these models, instructors did not have a veryclear idea of what exactly needed to be done, with manyexpressing uncertainty about the best way to assess studentprogress, prevent plagiarism, and ensure that students do notrely too heavily on the models, hindering their education. Intheir interviews, instructors did mention a few considerationsthey had for updating their assessment methods:•Mitigate plagiarism by developing engaging assignmentsand reducing busy work (I3)•Change course grade weights such that easily plagiarizedassignments can’t carry students’ grades (I4, I5) D ISCUSSION & C ONCLUSIONA. Converging Themes across Stakeholders and Opportunities In this section, we present converging themes that emergedthrough our stakeholder interviews. Based on these areas ofconvergence, we present some opportunities to maximize thebenefits of generative models in computing education settings. 1) Students and instructors are concerned about trustwor-thiness and over-reliance: Across most interviews, studentsand instructors were concerned about the trustworthiness ofGAI tools as well as the potential for students to become over-reliant on them. Participants highlighted the black-box natureof GAI and their tendency to hallucinate non-factual informa-tion. This raised concerns about students not understandingthe responses they receive from GAI, a lack of reliability ofthe information received, and the impact of over-reliance onstudents’ learning outcomes. Opportunity #1: Explicitly teach students when and how touse GAI tools. Educators can teach courses and modules abouthow to fact-check the model’s output in cases where the modelis known to perform poorly; calibrating a healthy skepticismin generative AI. Additionally, instructors should not assumecomputing students have AI literacy. It may be necessary toteach courses in computational thinking and AI literacy [47]. 2) Students and instructors believe GAI tools will broadenaccess: Students expressed that they believed tools like Chat-GPT are valuable learning tools, partially due to the fact thatit’s available at any time and it’s free or inexpensive to use. Opportunity #2: GAI tools democratize access to help. Similarto when unequal access to the Internet caused some students tobe left behind [15], today, unequal financial access to tutors,unpaid internships, college prep programs, and paid contentcan have similar effects. GAI tools may offer cheaper accessto high-quality tutoring. B. Diverging Themes across Stakeholders and Challenges In this section, we present some diverging themes whichhave the potential to cause tension between students andinstructors. We also describe how these divergences in prefer-ences may eventually lead to challenges. 1) Students tended to be more familiar and frequent usersof GAI tools than instructors: The majority of the studentswere either familiar with the capabilities of GAI tools or usethem frequently. On the contrary, some instructors had triedGAI tools, but they did not use them very frequently. Challenge #1: Instructors need to become familiar withthe functionality and limitations of GAI tools in order toadapt curricula and assessment methods adequately. Currently,instructors are at a disadvantage to students who are muchmore familiar with these models. 2) Students and instructors are not aligned on how to adaptassessment: While both stakeholders expressed uncertaintyabout how to adapt assessment methods to account for GAItools, the suggestions they did provide did not align. Studentsemphasized that the weight and frequency of hands-on, activelearning assignments, such as programming labs, should notchange as they are valuable to students’ comprehension of newmaterial and learning goals. A few of the instructors proposedto adapt their assessment methods to combat academic dishon-esty by reducing the weight of some of the lab assignmentsand increasing the weight or frequency of in-class, proctoredassignments, such as quizzes or tests. This divergence betweenthe values of students and instructors has the potential to createsignificant tension between students and instructors. Challenge #2: Instructors wanted to develop assessmentsthat mitigate academic dishonesty. One-third of interviewedinstructors suggested doing this by increasing the weightof proctored exams. However, students expressed that theystill want hands-on and active learning assignments (e.g.,programming lab assignments) to represent a larger portionof their overall grade, because, as many students expressed,they learned better when they were engaged in the tasks theyhad to complete. Increasing the frequency or weight of in-class proctored exams moves away from evidence-based activelearning [48], additionally it may negatively affect students. 3) Instructors were not aware of students’ motivations forusing GAI tools: Students shared a variety of reasons as towhy they would choose to use GAI tools to assist with or com-plete their assignments, such as reducing busy work, gettinganother perspective other than their instructor on a concept,and getting help when their instructor is not available. Wheninstructors were asked to consider why students use thesemodels, the only common response was regarding studentsusing GAI tools for busy work. Challenge #3: Instructors need to better understand stu-dents’ motivations for using GAI tools. Without this un-derstanding, instructors could potentially make changes topedagogy and assessment that unintentionally harm students. To address this concern, researchers and practitioners couldco-design solutions with students. Co-design is useful for cur-riculum design [49] and has already been used for integratingAI into classrooms [50]. These techniques may not only resultin better, more equitable solutions but also have the potentialto build relationships and leverage students’ deeper familiaritywith these GAI tools. C. ConclusionThis paper presents the first systematic investigation of bothstudents’ and instructors’ experiences with and preferencesfor using GAI tools in computing classrooms. While theseresults are preliminary, we believe that rapidly disseminatingthese critical views can guide researchers to capitalize onopportunities while mitigating potential challenges. REFERENCES[1] S. Sarsa, P. Denny, A. Hellas, and J. Leinonen, “Automatic generationof programming exercises and code explanations using large languagemodels,” in Proc. Computing EducationResearch - Volume 1 . ACM, 2022, p. 27–43.[2] S. MacNeil, A. Tran, J. Leinonen, P. Denny, J. Kim, A. Hellas, S. Bern-stein, and S. Sarsa, “Automatically generating cs learning materials withlarge language models,” arXiv preprint arXiv:2212.05113 , 2022. [Online]. Available: https://doi.org/10.1145/3545945.3569830[4] J. Finnie-Ansley, P. Denny, B. A. Becker, A. Luxton-Reilly, andJ. Prather, “The robots are coming: Exploring the implications ofopenai codex on introductory programming,” in Australasian ComputingEducation Conf. , 2022, pp. 10–19. [5] S. MacNeil, A. Tran, D. Mogil, S. Bernstein, E. Ross, and Z. Huang,“Generating diverse code explanations using the gpt-3 large languagemodel,” in Proc. Computing EducationResearch - Volume 2 . [6] S. MacNeil, A. Tran, A. Hellas, J. Kim, S. Sarsa, P. Denny, S. Bernstein,and J. Leinonen, “Experiences from using code explanations generatedby large language models in a web software development e-book,”inProceedings of the 54th ACM Technical Symposium on ComputerScience Education V . 1 , 2023, pp. [7] B. A. Becker, P. Denny, J. Finnie-Ansley, A. Luxton-Reilly, J. Prather,and E. A. Santos, “Programming is hard - or at least it used tobe: Educational opportunities and challenges of ai code generation,”inProceedings of the 54th ACM Technical Symposium on ComputerScience Education , ser. [Online]. Available:https://doi.org/10.1145/3545945.3569759[8] J. Savelka, A. Agarwal, C. Bogart, and M. Sakr, “Large language models(gpt) struggle to answer multiple-choice questions about code,” 2023. [9] J. Leinonen, P. Denny, S. MacNeil, S. Sarsa, S. Bernstein, J. Kim,A. Tran, and A. Hellas, “Comparing code explanations created bystudents and large language models,” in Proceedings of the 2023Conference on Innovation and Technology in Computer ScienceEducation V . [Online]. Available:https://doi.org/10.1145/3587102.3588785[10] A. Tran, L. Li, E. Rama, K. Angelikas, and S. MacNeil, “Using largelanguage models to automatically identify programming concepts incode snippets,” in Proc. of the 2023 ACM Conf. ComputingEducation Research - Volume 2 , vol. 1. ACM, 2023, pp. [11] S. MacNeil, J. Kim, J. Leinonen, P. Denny, S. Bernstein, B. A.Becker, M. Wermelinger, A. Hellas, A. Tran, S. Sarsa, J. Prather,and V . Kumar, “The implications of large language models for csteachers and students,” in Proceedings of the 54th ACM TechnicalSymposium on Computer Science Education V . [Online]. Available: https://doi.org/10.1145/3545947.3573358[12] E. Kasneci, K. Sessler, S. K ¨uchemann, M. Bannert, D. Dementieva,F. Fischer, U. Gasser, G. Groh, S. G ¨unnemann, E. H ¨ullermeier, S. Kr-usche, G. Kutyniok, T. Michaeli, C. Nerdel, J. Pfeffer, O. Poquet,M. Sailer, A. Schmidt, T. Seidel, M. Stadler, J. Weller, J. Kuhn, andG. Kasneci, “Chatgpt for good? on opportunities and challenges of largelanguage models for education,” Learning and Individual Differences ,vol. [13] J. Prather, P. Denny, J. Leinonen, B. A. Becker, I. Albluwi, M. E.Caspersen, M. Craig, H. Keuning, N. Kiesler, T. Kohn, A. Luxton-Reilly, S. MacNeil, A. Petersen, R. Pettit, B. N. Reeves, and J. Savelka,“Transformed by transformers: Navigating the ai coding revolution forcomputing education: An iticse working group conducted by humans,”inProceedings of the 2023 Conference on Innovation and Technologyin Computer Science Education V . [Online]. Available: https://doi.org/10.1145/3587103.3594206[14] S. Lau and P. J. Guo, “From” ban it till we understand it” to” resistanceis futile”: How university programming instructors plan to adapt as morestudents use ai code generation and explanation tools such as chatgpt andgithub copilot,” 2023. [Online]. Available: https://www.samlau.me/pubs/cs-instructors-adapting-to-chatgpt-copilot-ai-tools ICER-2023.pdf[15] J. Margolis, R. Estrella, J. Goode, J. J. Holme, and K. Nao, Stuck in theShallow End . [16] J. D. Basham, T. E. Hall, R. A. Carter Jr, and W. M. Stahl, “Anoperationalized understanding of personalized learning,” Journal ofSpecial Education Technology , vol. 31, no. 3, pp. [17] T. Crow, A. Luxton-Reilly, and B. Wuensche, “Intelligent tutoring sys-tems for programming education: a systematic review,” in Proceedingsof the 20th Australasian Computing Education Conference , 2018. [18] J. R. Anderson, C. F. Boyle, and B. J. Reiser, “Intelligent tutoringsystems,” Science , vol. 228, no. 4698, pp. [19] P. Leitner, M. Khalil, and M. Ebner, “Learning analytics in highereducation—a literature review,” Learning analytics: Fundaments, ap-plications, and trends: A view of the current state of the art to enhanceE-learning , pp. [20] B. Rienties, H. Køhler Simonsen, and C. Herodotou, “Defining theboundaries between artificial intelligence in education, computer-supported collaborative learning, educational data mining, and learninganalytics: A need for coherence,” in Frontiers in Education , vol. 5. [21] P. Ihantola, A. Vihavainen, A. Ahadi, M. Butler, J. B ¨orstler, S. H.Edwards, E. Isohanni, A. Korhonen, A. Petersen, K. Rivers et al. , “Edu-cational data mining and learning analytics in programming: Literaturereview and case studies,” Proceedings of the 2015 ITiCSE on WorkingGroup Reports , pp. [22] T. Cerratto Pargman and C. McGrath, “Mapping the ethics of learninganalytics in higher education: A systematic literature review of empiricalresearch,” Journal of Learning Analytics , vol. Aleven, “Student learning benefitsof a mixed-reality teacher awareness tool in ai-enhanced classrooms,” inArtificial Intelligence in Education , ser. Springer, 2018. [24] L. Chen, P. Chen, and Z. Lin, “Artificial intelligence in education: Areview,” IEEE Access , vol. 8, pp. [25] B. Puryear and G. Sprint, “Github copilot in the classroom: Learning tocode with ai assistance,” J. Comput. Coll. , vol. [27] M. O. Riedl, “Human-centered artificial intelligence and machine learn-ing,” Human Behavior and Emerging Technologies , vol. 1, no. 1, pp. [28] U. Ehsan and M. O. Riedl, “Human-centered explainable ai: HCI Interna-tional Conference, HCII 2020, Copenhagen, Denmark, July 19–24, 2020,Proceedings 22 . Springer, 2020, pp. [29] J. D. Lee and K. A. See, “Trust in automation: Designing for appropriatereliance,” Human factors , vol. 46, no. 1, pp. [30] K. A. Hoff and M. Bashir, “Trust in automation: Integrating empiricalevidence on factors that influence trust,” Human factors , vol. 57, no. 3,pp. Guttag, E. Colak, and M. Ghassemi, “Do as aisay: susceptibility in deployment of clinical decision-aids,” NPJ digitalmedicine , vol. MIS Quarterly Executive ,vol. 19, no. 4, 2020. Farahani, W. Karwowski, and T. Ahram, “Explainableartificial intelligence for education and training,” The Journal of DefenseModeling and Simulation , vol. 19, no. 2, pp. [34] H. Khosravi, S. B. Shum, G. Chen, C. Conati, Y .-S. Tsai, J. Kay,S. Knight, R. Martinez-Maldonado, S. Sadiq, and D. Ga ˇsevi´c, “Ex-plainable artificial intelligence in education,” Computers and Education:Artificial Intelligence , vol. [35] K. Peters and E. Halcomb, “Interviews in qualitative research,” Nurseresearcher , vol. 22, pp. [36] S. Heckman, J. C. Carver, M. Sherriff, and A. Al-zubidy, “A systematicliterature review of empiricism and norms of reporting in computingeducation research literature,” ACM Trans. Educ. , vol. 22, [Online]. Available: https://doi.org/10.1145/3470652[37] J. Sheard, S. Simon, M. Hamilton, and J. L ¨onnberg, “Analysisof research into the teaching and learning of programming,” inProceedings of the Fifth International Workshop on ComputingEducation Research Workshop , ser. [Online]. Available: https://doi.org/10.1145/1584322.1584334[38] A. Lishinski, J. Good, P. Sands, and A. Yadav, “Methodologicalrigor and theoretical foundations of cs education research,” inProceedings of the 2016 ACM Conference on International ComputingEducation Research , ser. [Online]. Available:https://doi.org/10.1145/2960310.2960328[39] S. Schulz, S. Berndt, and A. Hawlitschek, “Exploring students’ andlecturers’ views on collaboration and cooperation in computer sciencecourses - a qualitative analysis,” Computer Science Education , 01 2022. an investigation of cs instructor obstacles, workarounds,and desires,” in Proceedings of the 54th ACM Technical Symposiumon Computer Science Education V . [Online]. Available: https://doi.org/10.1145/3545945.3569816[41] B. T. J ´onsson, M. Pischetola, N. Inie, M. Daniels, and C. Brabrand,“Student perspectives on on-site versus online teaching throughout thecovid-19 pandemic,” in 2022 IEEE Frontiers in Education Conference(FIE) , 2022, pp. Cham: SpringerInternational Publishing, 2020, pp. [Online]. Available:https://doi.org/10.1007/978-3-319-24612-3 857[43] V . Clarke, “Using thematic analysis in psychology,”Qualitative Research in Psychology , vol. 3, no. 2, pp. [Online]. Available: https://www.tandfonline.com/doi/abs/10.1191/1478088706qp063oa[44] C. Zander, L. Thomas, J. E. Mostr ¨om, and A. Eckerdal, “Copying canbe good: How students view imitation as a tool in learning to program,”in2020 IEEE Frontiers in Education Conference (FIE) , 2020, pp. [45] L. van Beek, M. van den Bogaard, and M. de Vries, “Feedbackperceptions: preliminary analysis of semistructured group interviewswith first-year bachelor students of computer science,” in 2021 IEEEFrontiers in Education Conference (FIE) , 2021, pp. 1–8. [46] P. Drijvers and M. Doorman, “The graphics calculator in mathematicseducation,” The Journal of Mathematical Behavior , vol. 15, no. 4, pp. competencies anddesign considerations,” in Proceedings of the 2020 CHI Conference onHuman Factors in Computing Systems , ser. [Online]. Available: https://doi.org/10.1145/3313831.3376727[48] C. C. Bonwell and J. A. Eison, “Active Learning: Creating Excitementin the Classroom. 1991 ASHE-ERIC Higher Education Reports,” ERICClearinghouse on Higher Education, The George Washington University,One Dupont Circle, Suite 630, Washington, DC 20036-1183 ($17, Tech. [Online]. Available: https://eric.ed.gov/?id=ED336049[49] K. L. Gunckel and F. M. Moore, “Including Students and Teachersin the Co-Design of the Enacted Curriculum,” Tech. Online Submission ERIC Number: ED498676. [Online]. Available: https://eric.ed.gov/?id=ED498676[50] K. Holstein, B. M. McLaren, and V . Aleven, “Co-Designing aReal-Time Classroom Orchestration Tool to Support Teacher–AIComplementarity,” Journal of Learning Analytics , vol. 6, no. 2, pp. 27–52, Jul. 2019. [Online]. Available: https://learning-analytics.info/index.php/JLA/article/view/6336APPENDIXSemi-Structured Interview ScriptPersonal Background Information:1) (Students) 2) (Instructors) What courses do you teach? What kinds of assignmentsdo you to tend to have students complete? Awareness of GAI tools:1) Are you familiar with GAI tools like GitHub CoPilot,Amazon CodWhisperer, ChatGPT, Grammarly, or GoogleSmart Compose?” Prior Experiences with GAI tools:1) Have you ever used a GAI tool for an educational reason? If so, describe a time when you used a GAI tool to helpwith an assignment. What kind of assignment was it for? How was it help-ful/unhelpful? Would you use it again? Why did youchoose to use it? Values Held for GAI tools:1) (Students) 2) (Students) When would you use a tool like these inaddition to or instead of getting assistance from yourinstructor, teaching assistants, or peers?3) (Students) What types of assignments do you think arethe most beneficial to your ability to comprehend newmaterial? What situations do you think these tools could be bene-ficial for students? For instructors? What are your concerns for their usage by students? Byinstructors? How often do you believe students use tools like these toplagiarize work on assignments? What curriculum changes do you expect will be requiredas a result of these models?\n",
      "-----------------------------\n"
     ]
    }
   ],
   "source": [
    "print(f\"Search Query: {user_query}\")\n",
    "for score, idx, _ in result:\n",
    "    print(f\"Score: {score}\\nParagraph:\\n{org_data.iloc[idx][1]}\")\n",
    "    print(\"-----------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "762183de8d0d4a71936a5761213b4531",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/681M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e384c5d31b584254978e8f8192711652",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/2251 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6c4e90bfbce47589a90eae9ec2f49f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/2376 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5aafb5d7f12b46158f36b98bc9a3a89e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/570 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"ai2_arc\", \"ARC-Easy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "paragraphs_valid = dataset['validation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['id', 'question', 'choices', 'answerKey'],\n",
       "    num_rows: 570\n",
       "})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paragraphs_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_paragraphs_test(query, paragraphs):\n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "    \n",
    "    # Load Sentence Transformer model\n",
    "    model_name = \"all-mpnet-base-v2\"\n",
    "    sentence_transformer = SentenceTransformer(model_name)\n",
    "\n",
    "    # Extract content from the list of tuples\n",
    "    paragraph_contents = [str(para['question']) + \" \" + str(para['choices']) for para in paragraphs]\n",
    "  \n",
    "  # Rest of implementation\n",
    "\n",
    "    query_embedding = sentence_transformer.encode([query])[0]\n",
    "\n",
    "    paragraph_embeddings = sentence_transformer.encode(paragraph_contents)  \n",
    "\n",
    "    # Calculate cosine similarity\n",
    "    scores = util.pytorch_cos_sim(torch.tensor([query_embedding]), torch.tensor(paragraph_embeddings))[0]\n",
    "    scores = scores.cpu().numpy()\n",
    "\n",
    "    # Get the indices of top results\n",
    "    top_indices = scores.argsort()[::-1][:5]\n",
    "    \n",
    "      # Return paragraphs\n",
    "    top_results = []\n",
    "    for idx in top_indices:\n",
    "        para = paragraph_contents[idx]\n",
    "        top_results.append((scores[idx], idx,para))\n",
    "\n",
    "    return top_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MCAS_2016_8_3\n",
      "ACTAAP_2014_7_6\n",
      "MRR Score: 0.0\n"
     ]
    }
   ],
   "source": [
    "paragraphs_train = dataset['train']\n",
    "paragraphs_valid = dataset['validation']\n",
    "\n",
    "def test_search():\n",
    "\n",
    "  queries = [\"science technology\", \"chemistry research\"]\n",
    "  \n",
    "  rel_paragraphs = [paragraphs_valid[5], paragraphs_valid[2]]\n",
    "  \n",
    "  mrr_scores = []\n",
    "  \n",
    "  for query, rel_para in zip(queries, rel_paragraphs):\n",
    "  \n",
    "    results = search_paragraphs_test(query, paragraphs_train)\n",
    "    #print(results)\n",
    "    top_ids = [res[1] for res in results]\n",
    "    #print(top_ids)\n",
    "    rank = next((i for i, idx in enumerate(top_ids) if idx==rel_para['id']), None)\n",
    "    print(rel_para['id'])\n",
    "    if rank is not None:\n",
    "      mrr_scores.append(1/float(rank + 1))\n",
    "    else:\n",
    "      mrr_scores.append(0)\n",
    "      \n",
    "  mean_mrr = np.mean(mrr_scores)\n",
    "  \n",
    "  print(\"MRR Score:\", mean_mrr)\n",
    "\n",
    "  return mean_mrr,results\n",
    "  \n",
    "_, results = test_search()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Which of these involves the formation of a new chemical substance? {'text': ['evaporation of gasoline', 'mixing salt and pepper', 'dissolving sugar in tea', 'rusting of an iron chain'], 'label': ['A', 'B', 'C', 'D']}\""
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[0][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
